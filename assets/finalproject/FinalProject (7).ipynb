{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "368a82f7-56f3-47ea-bde3-fafd52f6ad7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff2eb4a4-0206-41d4-b819-1ad305284171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "file_path = '/Users/naveenashish/Downloads/repo10fb1_2.csv'\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c095e026-3c1f-40a8-9c94-bfe58e6f83e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8143"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, _ = train_test_split(data, test_size=0.9, stratify=data['faultbasis'])\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991202cd-3c68-49b5-97b9-29a44982686b",
   "metadata": {},
   "source": [
    "### Vectorize and scale the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d55b007c-7cdd-4ed0-b2f1-ee06ba9f88d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and scaled data shape: (8143, 25636)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>25626</th>\n",
       "      <th>25627</th>\n",
       "      <th>25628</th>\n",
       "      <th>25629</th>\n",
       "      <th>25630</th>\n",
       "      <th>25631</th>\n",
       "      <th>25632</th>\n",
       "      <th>25633</th>\n",
       "      <th>25634</th>\n",
       "      <th>25635</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.257403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.035402</td>\n",
       "      <td>-0.376509</td>\n",
       "      <td>-0.439118</td>\n",
       "      <td>-0.882810</td>\n",
       "      <td>1.049527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>-0.027155</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>-0.097062</td>\n",
       "      <td>-0.060809</td>\n",
       "      <td>-0.029332</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>-0.022169</td>\n",
       "      <td>-0.015674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.257403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.022518</td>\n",
       "      <td>-0.403969</td>\n",
       "      <td>-0.465997</td>\n",
       "      <td>0.998365</td>\n",
       "      <td>0.545291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>-0.027155</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>-0.097062</td>\n",
       "      <td>-0.060809</td>\n",
       "      <td>-0.029332</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>-0.022169</td>\n",
       "      <td>-0.015674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.257403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.037259</td>\n",
       "      <td>-0.403969</td>\n",
       "      <td>-0.465997</td>\n",
       "      <td>0.810248</td>\n",
       "      <td>0.041055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>-0.027155</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>-0.097062</td>\n",
       "      <td>-0.060809</td>\n",
       "      <td>-0.029332</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>-0.022169</td>\n",
       "      <td>-0.015674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.257403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.023678</td>\n",
       "      <td>-0.403969</td>\n",
       "      <td>2.324673</td>\n",
       "      <td>-1.259045</td>\n",
       "      <td>0.041055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>-0.027155</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>-0.097062</td>\n",
       "      <td>-0.060809</td>\n",
       "      <td>-0.029332</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>-0.022169</td>\n",
       "      <td>-0.015674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.257403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.036679</td>\n",
       "      <td>-0.403969</td>\n",
       "      <td>-0.465997</td>\n",
       "      <td>0.810248</td>\n",
       "      <td>0.545291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>-0.027155</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>-0.097062</td>\n",
       "      <td>-0.060809</td>\n",
       "      <td>-0.029332</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>-0.022169</td>\n",
       "      <td>-0.015674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25636 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1         2         3         4         5         6      7      \\\n",
       "0 -0.257403    0.0 -0.035402 -0.376509 -0.439118 -0.882810  1.049527    0.0   \n",
       "1 -0.257403    0.0 -0.022518 -0.403969 -0.465997  0.998365  0.545291    0.0   \n",
       "2 -0.257403    0.0 -0.037259 -0.403969 -0.465997  0.810248  0.041055    0.0   \n",
       "3 -0.257403    0.0 -0.023678 -0.403969  2.324673 -1.259045  0.041055    0.0   \n",
       "4 -0.257403    0.0 -0.036679 -0.403969 -0.465997  0.810248  0.545291    0.0   \n",
       "\n",
       "   8         9      ...     25626     25627     25628     25629     25630  \\\n",
       "0    0.0 -0.011082  ... -0.011082 -0.011082 -0.027155 -0.011082 -0.097062   \n",
       "1    0.0 -0.011082  ... -0.011082 -0.011082 -0.027155 -0.011082 -0.097062   \n",
       "2    0.0 -0.011082  ... -0.011082 -0.011082 -0.027155 -0.011082 -0.097062   \n",
       "3    0.0 -0.011082  ... -0.011082 -0.011082 -0.027155 -0.011082 -0.097062   \n",
       "4    0.0 -0.011082  ... -0.011082 -0.011082 -0.027155 -0.011082 -0.097062   \n",
       "\n",
       "      25631     25632     25633     25634     25635  \n",
       "0 -0.060809 -0.029332 -0.011082 -0.022169 -0.015674  \n",
       "1 -0.060809 -0.029332 -0.011082 -0.022169 -0.015674  \n",
       "2 -0.060809 -0.029332 -0.011082 -0.022169 -0.015674  \n",
       "3 -0.060809 -0.029332 -0.011082 -0.022169 -0.015674  \n",
       "4 -0.060809 -0.029332 -0.011082 -0.022169 -0.015674  \n",
       "\n",
       "[5 rows x 25636 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define columns for preprocessing\n",
    "numerical_features = ['modifications_count', 'additions_count', 'deletions_count', 'author_id', 'committer_id', 'hour', 'day', 'repo_id', 'ri']\n",
    "categorical_features = ['author_name', 'author_login', 'author_email', 'committer_name', 'committer_login', 'committer_email', 'commit_msg', 'parent_shas', 'faulty_commit', 'ext']\n",
    "\n",
    "# Create a pipeline for numerical features\n",
    "numerical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Impute missing values if any\n",
    "    ('scaler', StandardScaler())                 # Standardize features\n",
    "])\n",
    "\n",
    "\n",
    "# Create a pipeline for categorical features\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='NotAvailable')),  # Fill missing with \"NotAvailable\"\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))      # One-hot encode\n",
    "])\n",
    "# Combine pipelines into a column transformer\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numerical_pipeline, numerical_features),\n",
    "    ('cat', categorical_pipeline, categorical_features)\n",
    "])\n",
    "\n",
    "# Prepare the features (X) and target (y)\n",
    "X = data[numerical_features + categorical_features]\n",
    "y = data['faultbasis'].astype(int)\n",
    "\n",
    "# Apply the preprocessing\n",
    "X_transformed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Scale the combined features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_transformed)\n",
    "\n",
    "# Convert the processed data to a DataFrame for review (optional)\n",
    "X_scaled_df = pd.DataFrame(X_scaled)\n",
    "\n",
    "# Display the shape of the processed data and the first few rows to verify\n",
    "print(\"Processed and scaled data shape:\", X_scaled.shape)\n",
    "X_scaled_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441b9774-e228-454e-aec7-c0345fc2f8a1",
   "metadata": {},
   "source": [
    "### Create Tensors for DNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "266be084-8037-4a89-881a-823ddacaf841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert preprocessed data to PyTorch tensors\n",
    "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y.values, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14896dc0-ccc3-451d-a360-23076ecf6e47",
   "metadata": {},
   "source": [
    "### Build an elementary DNN and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2191011f-1880-49a7-9358-f160e19dd38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n",
      "Unique values in the target: tensor([1, 2])\n",
      "Number of classes: 3\n",
      "Epoch [1/20], Loss: 0.6044\n",
      "Epoch [2/20], Loss: 0.8444\n",
      "Epoch [3/20], Loss: 0.1497\n",
      "Epoch [4/20], Loss: 0.0715\n",
      "Epoch [5/20], Loss: 0.0435\n",
      "Epoch [6/20], Loss: 0.0258\n",
      "Epoch [7/20], Loss: 0.0164\n",
      "Epoch [8/20], Loss: 0.0118\n",
      "Epoch [9/20], Loss: 0.0091\n",
      "Epoch [10/20], Loss: 0.0077\n",
      "Epoch [11/20], Loss: 0.0068\n",
      "Epoch [12/20], Loss: 0.0060\n",
      "Epoch [13/20], Loss: 0.0056\n",
      "Epoch [14/20], Loss: 0.0052\n",
      "Epoch [15/20], Loss: 0.0049\n",
      "Epoch [16/20], Loss: 0.0049\n",
      "Epoch [17/20], Loss: 0.0046\n",
      "Epoch [18/20], Loss: 0.0044\n",
      "Epoch [19/20], Loss: 0.0043\n",
      "Epoch [20/20], Loss: 0.0042\n",
      "Test Accuracy: 92.94%\n"
     ]
    }
   ],
   "source": [
    "# Check unique values in the target to verify the range\n",
    "print(\"Unique values in the target:\", y_tensor.unique())\n",
    "\n",
    "# Update num_classes based on the unique values\n",
    "num_classes = y_tensor.max().item() + 1\n",
    "print(\"Number of classes:\", num_classes)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_size = int(0.8 * len(X_tensor))\n",
    "test_size = len(X_tensor) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(TensorDataset(X_tensor, y_tensor), [train_size, test_size])\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define a simple 2-layer DNN\n",
    "class SimpleDNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(SimpleDNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, 64)\n",
    "        self.layer2 = nn.Linear(64, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "# Get the input size\n",
    "input_size = X_tensor.shape[1]\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = SimpleDNN(input_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        outputs = model(X_batch)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += y_batch.size(0)\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Test Accuracy: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34101254-790d-42fa-9069-f7373d1d1130",
   "metadata": {},
   "source": [
    "### Accuracy is a misleading metric, we really interested in the prediction of the sparse target class = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f3f5e09-d0cd-4a08-b743-d0ced3daedb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.0714    0.0909    0.0800        55\n",
      "           2     0.9679    0.9587    0.9633      1574\n",
      "\n",
      "    accuracy                         0.9294      1629\n",
      "   macro avg     0.5197    0.5248    0.5216      1629\n",
      "weighted avg     0.9377    0.9294    0.9335      1629\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model and collect predictions and true labels\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        outputs = model(X_batch)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.numpy())\n",
    "        all_labels.extend(y_batch.numpy())\n",
    "\n",
    "# Print the precision, recall, and F1-score per class\n",
    "print(classification_report(all_labels, all_preds, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9170fde3-3a2c-4429-99fc-c693c9532019",
   "metadata": {},
   "source": [
    "#### Prepare sequences for RNN (though I wouldn't give away everything on the many ways to sequence this !)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28170e05-709f-4bf7-ac0c-078d4a5542d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c4/25m939rn45d1_yzhcnr3wl400000gn/T/ipykernel_16068/2031966263.py:30: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:281.)\n",
      "  X_sequences = torch.tensor(X_sequences, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "# Convert timestamps to datetime and sort data\n",
    "data['author_date'] = pd.to_datetime(data['author_date'])\n",
    "data.sort_values(by='author_date', inplace=True)\n",
    "\n",
    "# Feature engineering: Calculate time differences in seconds\n",
    "data['time_diff'] = data['author_date'].diff().dt.total_seconds().fillna(0)\n",
    "\n",
    "# Extract additional time-based features\n",
    "data['day_of_week'] = data['author_date'].dt.dayofweek\n",
    "data['hour_of_day'] = data['author_date'].dt.hour\n",
    "\n",
    "# Prepare the features and target\n",
    "features = ['modifications_count', 'additions_count', 'deletions_count', 'hour_of_day', 'day_of_week', 'time_diff']\n",
    "target = 'faultbasis'\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(data[features])\n",
    "y = data[target].values\n",
    "\n",
    "# Prepare sequences for RNN\n",
    "sequence_length = 10  # Adjust based on your needs\n",
    "X_sequences = []\n",
    "y_sequences = []\n",
    "\n",
    "for i in range(len(X) - sequence_length):\n",
    "    X_sequences.append(X[i:i+sequence_length])\n",
    "    y_sequences.append(y[i+sequence_length])\n",
    "\n",
    "X_sequences = torch.tensor(X_sequences, dtype=torch.float32)\n",
    "y_sequences = torch.tensor(y_sequences, dtype=torch.long)\n",
    "\n",
    "# Define a PyTorch dataset and dataloader\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "dataset = SequenceDataset(X_sequences, y_sequences)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0369d18-7fff-46ed-b787-1f69299e185e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in the target: [1 2]\n",
      "Number of classes: 3\n",
      "Epoch [1/20], Loss: 0.2005\n",
      "Epoch [2/20], Loss: 0.1393\n",
      "Epoch [3/20], Loss: 0.1386\n",
      "Epoch [4/20], Loss: 0.1370\n",
      "Epoch [5/20], Loss: 0.1361\n",
      "Epoch [6/20], Loss: 0.1364\n",
      "Epoch [7/20], Loss: 0.1363\n",
      "Epoch [8/20], Loss: 0.1371\n",
      "Epoch [9/20], Loss: 0.1369\n",
      "Epoch [10/20], Loss: 0.1366\n",
      "Epoch [11/20], Loss: 0.1399\n",
      "Epoch [12/20], Loss: 0.1355\n",
      "Epoch [13/20], Loss: 0.1370\n",
      "Epoch [14/20], Loss: 0.1339\n",
      "Epoch [15/20], Loss: 0.1360\n",
      "Epoch [16/20], Loss: 0.1326\n",
      "Epoch [17/20], Loss: 0.1328\n",
      "Epoch [18/20], Loss: 0.1322\n",
      "Epoch [19/20], Loss: 0.1309\n",
      "Epoch [20/20], Loss: 0.1340\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     1.0000    0.0040    0.0079       253\n",
      "           2     0.9690    1.0000    0.9843      7880\n",
      "\n",
      "    accuracy                         0.9690      8133\n",
      "   macro avg     0.9845    0.5020    0.4961      8133\n",
      "weighted avg     0.9700    0.9690    0.9539      8133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert sequences to numpy arrays before torch tensors\n",
    "X_sequences = np.array(X_sequences)\n",
    "y_sequences = np.array(y_sequences)\n",
    "\n",
    "X_sequences = torch.tensor(X_sequences, dtype=torch.float32)\n",
    "y_sequences = torch.tensor(y_sequences, dtype=torch.long)\n",
    "\n",
    "# Check unique values in the target to verify the range\n",
    "print(\"Unique values in the target:\", np.unique(y_sequences))\n",
    "\n",
    "# Update num_classes based on the unique values\n",
    "num_classes = y_sequences.max().item() + 1\n",
    "\n",
    "print(\"Number of classes:\", num_classes)\n",
    "\n",
    "# Define an RNN model with 2 LSTM layers\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=2):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc(out[:, -1, :])  # Use the last output for prediction\n",
    "        return out\n",
    "\n",
    "# Initialize the model with the correct number of classes\n",
    "input_size = X_sequences.shape[2]\n",
    "hidden_size = 64\n",
    "model = RNNModel(input_size, hidden_size, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the RNN\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in dataloader:\n",
    "        outputs = model(X_batch)\n",
    "        \n",
    "        # Ensure y_batch is in the correct range\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in dataloader:\n",
    "        outputs = model(X_batch)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.numpy())\n",
    "        all_labels.extend(y_batch.numpy())\n",
    "\n",
    "# Print the precision, recall, and F1-score per class\n",
    "print(classification_report(all_labels, all_preds, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483135d0-b48b-4e52-91da-47034dfa03d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
